{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter0414/rebayes/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-23 13:41:33.730794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-02-23 13:41:34.571575: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-02-23 13:41:34.571701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-02-23 13:41:34.571711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from functools import partial\n",
    "import time\n",
    "from typing import Callable, Sequence\n",
    "import collections.abc\n",
    "import warnings\n",
    "import copy\n",
    "from collections import deque\n",
    "from tqdm import trange\n",
    "\n",
    "import ml_collections\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow_probability.substrates.jax.distributions import MultivariateNormalFullCovariance as MVN\n",
    "from tensorflow_probability.substrates.jax.distributions import MultivariateNormalDiag as MVND\n",
    "from tqdm import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.training import train_state\n",
    "import jax\n",
    "from jax import jit, vmap, lax, jacfwd\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "jax.numpy.set_printoptions(suppress = True, precision=4)\n",
    "from rebayes.base import RebayesParams\n",
    "from rebayes.low_rank_filter.lofi import LoFiParams, RebayesLoFi\n",
    "import hparam_tune_clf as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    \"\"\"Load MNIST train and test datasets into memory.\"\"\"\n",
    "    ds_builder = tfds.builder('mnist')\n",
    "    ds_builder.download_and_prepare()\n",
    "    train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n",
    "    train_tvsplit_ds = tfds.as_numpy(ds_builder.as_dataset(split='train[:80%]', batch_size=-1))\n",
    "    val_tvsplit_ds = tfds.as_numpy(ds_builder.as_dataset(split='train[80%:]', batch_size=-1))\n",
    "    test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n",
    "    for ds in [train_ds, train_tvsplit_ds, val_tvsplit_ds, test_ds]:\n",
    "        ds['image'] = jnp.float32(ds['image']) / 255.\n",
    "    return train_ds, test_ds, train_tvsplit_ds, val_tvsplit_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 13:41:46.041988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/lib\n",
      "2023-02-23 13:41:46.042031: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds, train_tvsplit_ds, val_tvsplit_ds = get_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = jnp.array(train_ds['image']), jnp.array(train_ds['label'])\n",
    "X_test, y_test = jnp.array(test_ds['image']), jnp.array(test_ds['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data\n",
    "X_train = X_train.reshape(-1, 1, 28, 28, 1)\n",
    "y_train_ohe = jax.nn.one_hot(y_train, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=128)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=10)(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    features: Sequence[int]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = x.ravel()\n",
    "        for feat in self.features[:-1]:\n",
    "            x = nn.relu(nn.Dense(feat)(x))\n",
    "        x = nn.Dense(self.features[-1])(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params size = (421642,)\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "key = jr.PRNGKey(0)\n",
    "params = cnn.init(key, jnp.ones([1, 28, 28, 1]))['params']\n",
    "flat_params, unflatten_fn = ravel_pytree(params)\n",
    "print(f'Params size = {flat_params.shape}')\n",
    "state_dim = flat_params.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_fn = lambda w, x: cnn.apply({'params': unflatten_fn(w)}, x).ravel()\n",
    "emission_mean_function=lambda w, x: jax.nn.softmax(apply_fn(w, x))\n",
    "def emission_cov_function(w, x):\n",
    "    ps = emission_mean_function(w, x)\n",
    "    return jnp.diag(ps) - jnp.outer(ps, ps) + 1e-3 * jnp.eye(len(ps)) # Add diagonal to avoid singularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_neg_log_likelihood(flat_params, unflatten_fn, apply_fn, test_set):\n",
    "    \"\"\" Evaluate negative log likelihood for given parameters and test set\n",
    "    \"\"\"\n",
    "    @jit\n",
    "    def evaluate_nll(label, image):\n",
    "        image = image.reshape((1, 28, 28, 1))\n",
    "        logits = apply_fn(flat_params, image)\n",
    "        return optax.softmax_cross_entropy_with_integer_labels(logits=logits, labels=label)\n",
    "    nlls = vmap(evaluate_nll, (0, 0))(test_set['label'], test_set['image'])\n",
    "    return nlls.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(\n",
    "    optimizer='sgd',\n",
    "    learning_rate=0.01, \n",
    "    momentum=2e-1,\n",
    "    init_var=3e-2,\n",
    "    num_iter=1,\n",
    "    batch_size=1, \n",
    "    num_epochs=1,\n",
    "    sample_freq=500,\n",
    "    posterior_predictive_method='mc',\n",
    "    seed=0\n",
    "    ):\n",
    "    \"\"\"Get the default hyperparameter configuration.\"\"\"\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.optimizer = optimizer\n",
    "    config.learning_rate = learning_rate\n",
    "    config.momentum = momentum\n",
    "    config.init_var = init_var\n",
    "    config.num_iter = num_iter\n",
    "    config.batch_size = batch_size\n",
    "    config.num_epochs = num_epochs\n",
    "    config.sample_freq = sample_freq\n",
    "    config.posterior_predictive_method = posterior_predictive_method\n",
    "    config.seed = seed\n",
    "    return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Orth-SVD LoFi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lofi_opt_fn(log_init_cov, log_dynamics_cov, log_alpha, memory_size, method='orth_svd_lofi'):\n",
    "    model_params = RebayesParams(\n",
    "        initial_mean=flat_params,\n",
    "        initial_covariance=jnp.power(10, log_init_cov),\n",
    "        dynamics_weights=1.0,\n",
    "        dynamics_covariance=jnp.power(10, log_dynamics_cov),\n",
    "        emission_mean_function=emission_mean_function,\n",
    "        emission_cov_function=emission_cov_function,\n",
    "        dynamics_covariance_inflation_factor=jnp.power(10, log_alpha)\n",
    "    )\n",
    "    lofi_params = LoFiParams(\n",
    "        memory_size=int(memory_size),\n",
    "    )\n",
    "    orfit_estimator = RebayesLoFi(model_params, lofi_params, method=method)\n",
    "\n",
    "    lls = []\n",
    "    orfit_bel = orfit_estimator.init_bel()\n",
    "    for i in range(0, 701, 100):\n",
    "        for j in range(i, i+100):\n",
    "            orfit_bel = orfit_estimator.predict_state(orfit_bel)\n",
    "            orfit_bel = orfit_estimator.update_state(orfit_bel, X_train[j], y_train_ohe[j])\n",
    "        orfit_mean = orfit_bel.mean\n",
    "        log_likelihood = -evaluate_neg_log_likelihood(orfit_mean, unflatten_fn, apply_fn, test_ds)\n",
    "        lls.append(log_likelihood)\n",
    "\n",
    "    return jnp.array(lls).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_lofi_opt_fn = partial(lofi_opt_fn, memory_size=20, method='orth_svd_lofi')\n",
    "os_lofi_optimizer = BayesianOptimization(\n",
    "    f=os_lofi_opt_fn,\n",
    "    pbounds={\n",
    "        'log_init_cov': (-6, -0.1),\n",
    "        'log_dynamics_cov': (-6, -0.1),\n",
    "        'log_alpha': (-6, -0.1),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | log_alpha | log_dy... | log_in... |\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "os_lofi_optimizer.maximize(\n",
    "    init_points=25,\n",
    "    n_iter=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a63216e3e6a2ce617ef04b00f48ca414857cfc892c8cff43a5943fdd36fca11d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
