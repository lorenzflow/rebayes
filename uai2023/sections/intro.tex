

\section{Introduction}


Suppose we observe a stream of labeled observations,
$\data_t=
\{(\vx_t^n, \vy_t^n) \sim p_t(\vx,\vy): n=1:N_t\}$, where $\vx_t^n \in \calX = \real^D$,
$\vy_t^n \in \calY = \real^C$,
and $N_t$ is the number of examples revealed
per time step.
(For notational simplicity, we henceforth assume
$N_t=1$.)
We want to use this to fit a prediction model $h: (\calX, \Theta) \ra \calY$, where $\vtheta \in \Theta = \real^P$ are the parameters of the model.
We focus on the case where $h$ is a deep neural network (DNN),
although in principle our methods can also be applied to other (differentiable) parametric models.

Since the data distribution $p_t(\vx,\vy)$ may change over time
---
especially in problem domains like 
recommender systems  \citep{Huang2015},
robotics \citep{Wolczyk2021,Lesort2020},
and sensor networks \citep{Ditzler2015}
---
we also allow the model parameters $\vtheta_t$ to change.
At each step, our goal is to recursively estimate the posterior 
\begin{align}
p(\vtheta_t|\data_{1:t})
 \propto p(\vy_t|\vx_t,\vtheta_t) p(\vtheta_t|\data_{1:t-1})
 \label{eqn:post}
\end{align}
in a fully online fashion, without having
to store past data.\footnote{
%
We do not assume access to any information
about when the distribution shifts
(sometimes called a ``task boundary''),
since such information is not usually available.
Furthermore,  the shifts may be gradual, which makes the concept of task boundary ill-defined.
} %
To compute the posterior, we need to specify a likelihood and prior. For the likelihood 
$p(\vy_t|\vx_t,\vtheta_t)$
we use
\begin{align}
    p(\vy_t|\vx_t,\vtheta_t) &= 
    \begin{cases}
    \gauss(\vy_t|h(\vx_t,\vtheta_t), \lambda^{-1}\vI)
     & \mbox{reg} \\
     \cat(\vy_t|h(\vx_t,\vtheta_t)) %mj: removed softmax here so that $f$ can be taken to output probabilities, which simplifies definition of $F$
     & \mbox{cls} 
    \end{cases}
    \label{eqn:likelihood}
\end{align}
The prior $p(\vtheta_t|\data_{1:t-1})$
is given by the one-step-ahead predictive distribution 
\begin{align}
p(\vtheta_t |\data_{1:t-1}) = \int p(\vtheta_t|\vtheta_{t-1})
p(\vtheta_{t-1} | \data_{1:t-1}) d \vtheta_{t-1}
\label{eqn:prior-predictive}
\end{align}
which we initialize using 
$p(\vtheta_0) = \gauss(\vmu_0=\vzero, \eta_0^{-1} \vI)$.
From this,
we can compute the posterior predictive distribution,
\begin{align}
  p(\vy_t|\vx_t,\data_{1:t-1}) = \int p(\vy_t|\vx_t,\vtheta_t) p(\vtheta_t|\data_{1:t-1}) d\vtheta_t
  \label{eqn:post-pred}
  \end{align}
which can be used for many kinds of sequential
decision making,
such as
active learning \citep{Holzmuller2022},
Bayesian optimization \citep{Garnett2023},
contextual bandits \citep{Duran-Martin2022},
and reinforcement learning \citep{Khetarpal2022,Wang2021}.


The dynamics model for  the latent state $\vtheta_t$
is assumed to have the form 
\begin{align}
p_t(\vtheta_t|\vtheta_{t-1}) &= 
\gauss(\vtheta_t  | \vF \vtheta_{t-1}, \vQ)
\label{eqn:dynamics}
\end{align}
If we set $\vQ = 0 \Id$ and $\vF=\Id$, this corresponds to a deterministic model in which the parameters do not change, i.e., 
\begin{align}
p_t(\vtheta_t|\vtheta_{t-1}) &= 
\delta(\vtheta_t  - \vtheta_{t-1}) \label{eq:stationary}
\end{align}
This is a useful special case for when we want to estimate the parameters from a stream of data coming from
a static distribution.
In the non-stationary case, 
we will use $\vQ = q \Id$ and $\vF = \gamma \Id$,
where $q >0$ and $\gamma<1$.
This  is a discretized version
of the Ornstein-Uhlenbeck noise process.
%(This prior was also used in \citep{Kurle2020}.)
(If $\gamma=0$, it corresponds to a Wiener or random
walk process.)
Using $q>0$ injects some noise at each time step,
and ensures that the model does not lose
"plasticity", so it can continue to learn online (c.f., \citep{Ash2020,Dohare2021}).\footnote{
%
Note that allowing for $q>0$
can be useful even for static problems,
since it can ameliorate the errors
introduced by linearization \citep{Barrau2018}.
}
Using $0 < \gamma < 1$ ensures that
the posterior will drift back to the prior of 0,
if the  likelihood is uninformative.

Computing \cref{eqn:post}
corresponds to recursive Bayesian inference (filtering)
in a state space model,
where the
dynamics model
in \cref{eqn:dynamics}
is linear Gaussian,
but the observation model
in \cref{eqn:likelihood}
is
non-linear and possibly non-Gaussian.
Many approximate algorithms have been proposed
for this task (see e.g.,  \citep{Sarkka23,pml2Book}),
but in this paper, we focus on Gaussian approximations
to the posterior, $q(\vtheta_t|\data_{1:t}) =\gauss(\vmu_t,\vS_t)$,
since they strike a good balance between 
efficiency and expressivity.
In particular, we build on the extended
Kalman filter (EKF), which linearizes the observation model at each step, and then computes a closed form Gaussian update.

The use of the EKF for online training of neural networks
was first proposed in \citep{Singhal1988},
and was extended to exponential family likelihoods
in \citep{Ollivier2018,Tronarp2018}.
The main drawback of the EKF is that it takes $O(\nparams^3)$ time per step,
where $\nparams = |\vtheta_t|$ is the number of parameters in the hidden  state vector,
because we need to invert the posterior covariance matrix $\vS_t$.
It is possible to derive diagonal approximations to the posterior covariance or precision,
by either minimizing 
$\KLpq{p(\vtheta_t|\data_{1:t})}{q(\vtheta_t)}$
or
$\KLpq{q(\vtheta_t)}{p(\vtheta_t|\data_{1:t})}$,
as discussed in \citep{Puskorius1991,Chang2022}.
These methods take $O(\nparams)$ time per step,
but can be much less statistically efficient
than full-covariance methods, since they ignore
correlations between the parameters.
This makes the method slower to learn,
and slower to adapt to changes in the data distribuitio.

In this paper, we propose an efficient and fully online way to compute a low-rank approximation to the precision, $\vS_t^{-1} = \eta\vI + \vW_t\vW_t^\T$, where $\vW_t\in\real^{\nparams \times \memory}$ for some memory limit $\memory$.
The key insight is that at each step, after we linearize the observation model, we can use the resulting gradient vector or Jacobian as "pseudo-observation(s)" that we append to $\vW_{t-1}$, and then we can perform an efficient online SVD approximation to obtain $\vW_t$.
This ensures the non-spherical part of the posterior precision remains low-rank.
%and minimizes interference with previous gradients.
We therefore call our method \lofi,
which is short for low-rank extended Kalman filter.
We show experimentally that this approach works better than diagonal approximations to the EKF,
as well as a state of the art methods
based on  SGD  with a replay buffer
 \citep{Cai2021}.
%(see e.g., \citep{Hu2021onepass}).


    











