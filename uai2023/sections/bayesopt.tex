\section{Bayesian optimization}

%We follow the notation of \citep{Paria2022}.




\begin{algorithm}
\dontprintsemicolon
\caption{Bayesian optimization}
\label{algo:bayesOpt}
Input: oracle $f^*(\vx)$, finite domain $\calX$, 
parameters $T_e$, $T$\\
Initialize observed dataset $\data_0 = \emptyset$\\
Initialize search space $\calX_0 = \calX$\\
// Initial random exploration (warmup) \\
\For{$t=1:T_e$}{
Sample $\vx_t \in \calX_t$ // uniformly at random \\
$y_t = f^*(\vx_t)$ // query the oracle \\
$\data_t = \data_{t-1} \union \{ (\vx_t,y_y) \}$ // record outcome \\ 
$\calX_t = \calX_t - \{ \vx_t \}$ // remove point from query set
}
$b_t = \text{init}(\data_t)$ \\
$M_t = \max_{y \in \data_t} y$ \\
\For{$t=T_e+1:T$}{
 \For{$\vx \in \calX_t$}{
   $\mu,\sigma = b_t.\text{predict}(\vx)$ \\
$\alpha(\vx) = \text{EI}(\mu,\sigma,M_t)$ // acquisition fn.\\ 
 }
 $\vx_t = \argmax_{\vx \in \calX_t} \alpha(\vx)$ \\
 $y_t = f^*(\vx_t)$ // query the oracle \\
$\data_t = \data_{t-1} \union \{ (\vx_t,y_y) \}$ \\
$M_t = \max(M_{t-1}, y_t)$ \\
$\calX_t = \calX_{t-1} - \{ \vx_t \}$ \\
$b_t = \text{update}(b_{t-1}, (\vx_t, y_t))$
}
\end{algorithm}

In \cref{algo:bayesOpt} we show a standard Bayesian optimization loop
(see e.g., \cite{Garnett2023}).
The most common acquisition function is
 the expected improvement (EI), given by
\begin{align}
\text{EI}(\mu, \sigma, M)
 = (\mu - M) \Phi(\gamma)
 + \sigma \phi(\gamma)
\end{align}
where $\phi()$ is the pdf of the $\gauss(0,1)$
distribution, $\Phi$ is the cdf, and 
\begin{align}
\gamma = \frac{\mu-M}{\sigma}
\end{align}